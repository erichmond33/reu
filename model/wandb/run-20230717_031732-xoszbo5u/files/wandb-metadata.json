{
    "os": "Linux-4.15.0-39-generic-x86_64-with-glibc2.27",
    "python": "3.10.11",
    "heartbeatAt": "2023-07-17T03:17:33.260298",
    "startedAt": "2023-07-17T03:17:32.779561",
    "docker": null,
    "cuda": null,
    "args": [
        "--local_rank=0",
        "--model_name_or_path=EleutherAI/gpt-neo-1.3B",
        "--per_device_train_batch_size=4",
        "--num_train_epochs",
        "30",
        "--save_strategy=steps",
        "--save_steps",
        "1150",
        "--output_dir=finetune_toolformer_v0",
        "--report_to",
        "wandb",
        "--dataset_name",
        "eerichmond33/sourceformer-dataset",
        "--tokenizer_name",
        "EleutherAI/gpt-neo-1.3B",
        "--block_size",
        "2048",
        "--gradient_accumulation_steps",
        "1",
        "--do_train",
        "--do_eval",
        "--evaluation_strategy=epoch",
        "--logging_strategy=epoch",
        "--fp16",
        "--overwrite_output_dir",
        "--adam_beta1=0.9",
        "--adam_beta2=0.999",
        "--weight_decay=2e-02",
        "--learning_rate=1e-05",
        "--warmup_steps=100",
        "--per_device_eval_batch_size=1",
        "--cache_dir=hf_cache",
        "--gradient_checkpointing=True",
        "--deepspeed",
        "ds_config_gpt_j.json"
    ],
    "state": "running",
    "program": "/home/eli.richmond/reu/train_gptj_toolformer.py",
    "codePath": "train_gptj_toolformer.py",
    "git": {
        "remote": "https://github.com/erichmond33/reu.git",
        "commit": "cf9cbab25f32ef44e20f20399cd072f220d5a731"
    },
    "email": "eerichmond33@gmail.com",
    "root": "/home/eli.richmond/reu",
    "host": "lostforty",
    "username": "eli.richmond",
    "executable": "/home/eli.richmond/miniconda3/envs/py310/bin/python",
    "cpu_count": 16,
    "cpu_count_logical": 32,
    "cpu_freq": {
        "current": 1453.5356250000007,
        "min": 800.0,
        "max": 2101.0
    },
    "cpu_freq_per_core": [
        {
            "current": 800.087,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.511,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 1369.525,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 863.254,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2399.542,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.24,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2712.167,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.015,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 801.26,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2575.719,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 801.115,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 1064.217,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2580.128,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 978.068,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2394.769,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.25,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.13,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 1377.87,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 876.869,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2728.358,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.93,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2402.436,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.437,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.58,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2399.917,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.609,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 1298.856,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2401.966,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 1450.93,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2591.525,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.874,
            "min": 800.0,
            "max": 2101.0
        }
    ],
    "disk": {
        "total": 219.05793380737305,
        "used": 66.00554656982422
    },
    "gpu": "Tesla V100-PCIE-32GB",
    "gpu_count": 2,
    "gpu_devices": [
        {
            "name": "Tesla V100-PCIE-32GB",
            "memory_total": 34089730048
        },
        {
            "name": "Tesla P40",
            "memory_total": 24032378880
        }
    ],
    "memory": {
        "total": 125.58304977416992
    }
}
