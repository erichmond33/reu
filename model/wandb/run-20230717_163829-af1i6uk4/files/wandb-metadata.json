{
    "os": "Linux-4.15.0-39-generic-x86_64-with-glibc2.27",
    "python": "3.10.11",
    "heartbeatAt": "2023-07-17T16:38:30.418270",
    "startedAt": "2023-07-17T16:38:29.909841",
    "docker": null,
    "cuda": null,
    "args": [
        "--local_rank=0",
        "--model_name_or_path=EleutherAI/gpt-neo-125m",
        "--per_device_train_batch_size=8",
        "--num_train_epochs",
        "1",
        "--save_strategy",
        "epoch",
        "--output_dir=finetune_toolformer_v0",
        "--report_to",
        "wandb",
        "--dataset_name",
        "eerichmond33/sourceformer-dataset",
        "--tokenizer_name",
        "EleutherAI/gpt-neo-125m",
        "--block_size",
        "2048",
        "--gradient_accumulation_steps",
        "1",
        "--do_train",
        "--do_eval",
        "--evaluation_strategy=epoch",
        "--logging_strategy=epoch",
        "--fp16",
        "--overwrite_output_dir",
        "--adam_beta1=0.9",
        "--adam_beta2=0.999",
        "--weight_decay=2e-02",
        "--learning_rate=1e-05",
        "--warmup_steps=100",
        "--per_device_eval_batch_size=1",
        "--cache_dir=hf_cache",
        "--gradient_checkpointing=True",
        "--deepspeed",
        "ds_config_gpt_j.json",
        "--push_to_hub=True"
    ],
    "state": "running",
    "program": "/home/eli.richmond/reu/train_gptj_toolformer.py",
    "codePath": "train_gptj_toolformer.py",
    "git": {
        "remote": "https://github.com/erichmond33/reu.git",
        "commit": "cf9cbab25f32ef44e20f20399cd072f220d5a731"
    },
    "email": "eerichmond33@gmail.com",
    "root": "/home/eli.richmond/reu",
    "host": "lostforty",
    "username": "eli.richmond",
    "executable": "/home/eli.richmond/miniconda3/envs/py310/bin/python",
    "cpu_count": 16,
    "cpu_count_logical": 32,
    "cpu_freq": {
        "current": 1287.23015625,
        "min": 800.0,
        "max": 2101.0
    },
    "cpu_freq_per_core": [
        {
            "current": 800.053,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.144,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 885.094,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2712.128,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.941,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2399.763,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 1017.778,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 823.495,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.663,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.51,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2638.276,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.41,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.394,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 1110.957,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.157,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2654.173,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.527,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.464,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 880.107,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2562.947,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.146,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2723.067,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 1165.789,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 853.843,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.162,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.212,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2400.614,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.507,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.771,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 1200.013,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 800.336,
            "min": 800.0,
            "max": 2101.0
        },
        {
            "current": 2399.522,
            "min": 800.0,
            "max": 2101.0
        }
    ],
    "disk": {
        "total": 219.05793380737305,
        "used": 66.01383209228516
    },
    "gpu": "Tesla V100-PCIE-32GB",
    "gpu_count": 2,
    "gpu_devices": [
        {
            "name": "Tesla V100-PCIE-32GB",
            "memory_total": 34089730048
        },
        {
            "name": "Tesla P40",
            "memory_total": 24032378880
        }
    ],
    "memory": {
        "total": 125.58304977416992
    }
}
